{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# def preprocess_data(data):\n",
    "#     data = data.select_dtypes(include=[np.number]).interpolate().dropna()\n",
    "#     return data\n",
    "## 代码修改\n",
    "def preprocess_data(data):\n",
    "    # 选择数值特征并填充缺失值\n",
    "    data = data.select_dtypes(include=[np.number]).interpolate().fillna(0)\n",
    "    \n",
    "    # 对于分类变量可以进行独热编码（举例）\n",
    "    data = pd.get_dummies(data, drop_first=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = preprocess_data(train_data)\n",
    "test_data = preprocess_data(test_data)\n",
    "\n",
    "# X = train_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "# X_test = test_data.drop('Id', axis=1)\n",
    "# y = train_data['SalePrice']\n",
    "## 代码修改\n",
    "X = train_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "# # Standardize data\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X_test = scaler.transform(X_test)\n",
    "## 代码修改\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_data.drop('Id', axis=1))\n",
    "\n",
    "# # Convert to PyTorch tensors\n",
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "# X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "## 代码修改\n",
    "# 转为 PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Train loss: 633048.8125, Val loss: 3920125.7500\n",
      "Fold 2, Train loss: 598368.9375, Val loss: 4976763.0000\n",
      "Fold 3, Train loss: 382419.3750, Val loss: 16213292.0000\n",
      "Fold 4, Train loss: 722786.4375, Val loss: 3079602.2500\n",
      "Fold 5, Train loss: 787075.6250, Val loss: 2310893.7500\n"
     ]
    }
   ],
   "source": [
    "# # K-Fold Cross Validation\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# fold = 1\n",
    "# for train_index, val_index in kf.split(X):\n",
    "#     X_train, X_val = X[train_index], X[val_index]\n",
    "#     y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "#     train_dataset = TensorDataset(X_train, y_train)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "#     model = HousePriceModel(input_dim)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    \n",
    "#     # Train the model\n",
    "#     epochs = 100\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         for batch_X, batch_y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(batch_X)\n",
    "#             loss = criterion(outputs, batch_y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "        \n",
    "#     model.eval()\n",
    "#     outputs = model(X_train)\n",
    "#     loss = criterion(outputs, y_train) / len(y_train)\n",
    "#     val_outputs = model(X_val)\n",
    "#     val_loss = criterion(val_outputs, y_val) / len(y_val)\n",
    "    \n",
    "#     print(f'Fold {fold}, Train loss: {loss.item():.4f}, Val loss: {val_loss.item():.4f}')\n",
    "#     fold += 1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # 定义 DataLoader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = HousePriceModel(input_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    \n",
    "    # 训练模型\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                val_outputs = model(batch_X)\n",
    "                val_loss += criterion(val_outputs, batch_y).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "    print(f'Fold {fold+1}, Validation Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用完整的训练数据集来重新训练模型，并进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "Epoch 10, Loss: 1646694.7500\n",
      "Epoch 20, Loss: 877657.8750\n",
      "Epoch 30, Loss: 685139.4375\n",
      "Epoch 40, Loss: 598490.1875\n",
      "Epoch 50, Loss: 554356.5000\n",
      "Epoch 60, Loss: 527653.8125\n",
      "Epoch 70, Loss: 510138.0312\n",
      "Epoch 80, Loss: 482555.0938\n",
      "Epoch 90, Loss: 470342.5312\n",
      "Epoch 100, Loss: 458880.2500\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "print(len(train_loader))\n",
    "# Train the model\n",
    "model = HousePriceModel(input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y) / len(y)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "model.eval()\n",
    "predictions = model(X_test).detach().numpy()\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': predictions.flatten()})\n",
    "submission.to_csv('submission_LianChen.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatunivi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

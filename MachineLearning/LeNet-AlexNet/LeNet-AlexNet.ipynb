{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取Fashion MINST数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_data = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_data)))\n",
    "print('Validation set has {} instances'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "            nn.Linear(120, 84), nn.Sigmoid(),\n",
    "            nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.351736  [   64/60000]\n",
      "loss: 2.288934  [ 6464/60000]\n",
      "loss: 2.311120  [12864/60000]\n",
      "loss: 2.326550  [19264/60000]\n",
      "loss: 2.294600  [25664/60000]\n",
      "loss: 2.297251  [32064/60000]\n",
      "loss: 2.296643  [38464/60000]\n",
      "loss: 2.309734  [44864/60000]\n",
      "loss: 2.290174  [51264/60000]\n",
      "loss: 2.303752  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.286048 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.297568  [   64/60000]\n",
      "loss: 1.960693  [ 6464/60000]\n",
      "loss: 1.713833  [12864/60000]\n",
      "loss: 1.419917  [19264/60000]\n",
      "loss: 1.014244  [25664/60000]\n",
      "loss: 1.030586  [32064/60000]\n",
      "loss: 0.944143  [38464/60000]\n",
      "loss: 0.911985  [44864/60000]\n",
      "loss: 0.591872  [51264/60000]\n",
      "loss: 1.057124  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.893366 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.662422  [   64/60000]\n",
      "loss: 0.794277  [ 6464/60000]\n",
      "loss: 0.835073  [12864/60000]\n",
      "loss: 0.692554  [19264/60000]\n",
      "loss: 0.669855  [25664/60000]\n",
      "loss: 0.657540  [32064/60000]\n",
      "loss: 0.765494  [38464/60000]\n",
      "loss: 0.472553  [44864/60000]\n",
      "loss: 0.514478  [51264/60000]\n",
      "loss: 0.557439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.597356 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.017996  [   64/60000]\n",
      "loss: 0.566663  [ 6464/60000]\n",
      "loss: 0.613441  [12864/60000]\n",
      "loss: 0.463998  [19264/60000]\n",
      "loss: 0.554033  [25664/60000]\n",
      "loss: 0.472040  [32064/60000]\n",
      "loss: 0.704041  [38464/60000]\n",
      "loss: 0.689127  [44864/60000]\n",
      "loss: 0.568726  [51264/60000]\n",
      "loss: 0.639774  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.522047 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.439553  [   64/60000]\n",
      "loss: 0.387449  [ 6464/60000]\n",
      "loss: 0.403983  [12864/60000]\n",
      "loss: 0.389036  [19264/60000]\n",
      "loss: 0.503581  [25664/60000]\n",
      "loss: 0.462875  [32064/60000]\n",
      "loss: 0.490427  [38464/60000]\n",
      "loss: 0.347460  [44864/60000]\n",
      "loss: 0.532564  [51264/60000]\n",
      "loss: 0.253152  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.508657 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.710985  [   64/60000]\n",
      "loss: 0.370720  [ 6464/60000]\n",
      "loss: 0.603156  [12864/60000]\n",
      "loss: 0.430042  [19264/60000]\n",
      "loss: 0.380019  [25664/60000]\n",
      "loss: 0.361622  [32064/60000]\n",
      "loss: 0.442907  [38464/60000]\n",
      "loss: 0.396473  [44864/60000]\n",
      "loss: 0.369300  [51264/60000]\n",
      "loss: 0.268497  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.520814 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.628299  [   64/60000]\n",
      "loss: 0.338480  [ 6464/60000]\n",
      "loss: 0.385880  [12864/60000]\n",
      "loss: 0.324799  [19264/60000]\n",
      "loss: 0.475392  [25664/60000]\n",
      "loss: 0.576892  [32064/60000]\n",
      "loss: 0.389486  [38464/60000]\n",
      "loss: 0.521989  [44864/60000]\n",
      "loss: 0.328435  [51264/60000]\n",
      "loss: 0.570348  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.435757 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.448183  [   64/60000]\n",
      "loss: 0.451486  [ 6464/60000]\n",
      "loss: 0.366442  [12864/60000]\n",
      "loss: 0.463588  [19264/60000]\n",
      "loss: 0.507942  [25664/60000]\n",
      "loss: 0.755150  [32064/60000]\n",
      "loss: 0.394968  [38464/60000]\n",
      "loss: 0.318922  [44864/60000]\n",
      "loss: 0.376684  [51264/60000]\n",
      "loss: 0.345236  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.441396 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.462360  [   64/60000]\n",
      "loss: 0.316430  [ 6464/60000]\n",
      "loss: 0.493872  [12864/60000]\n",
      "loss: 0.302434  [19264/60000]\n",
      "loss: 0.326119  [25664/60000]\n",
      "loss: 0.640207  [32064/60000]\n",
      "loss: 0.343983  [38464/60000]\n",
      "loss: 0.334465  [44864/60000]\n",
      "loss: 0.515424  [51264/60000]\n",
      "loss: 0.326502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.410385 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.495325  [   64/60000]\n",
      "loss: 0.183110  [ 6464/60000]\n",
      "loss: 0.324256  [12864/60000]\n",
      "loss: 0.502823  [19264/60000]\n",
      "loss: 0.494116  [25664/60000]\n",
      "loss: 0.348821  [32064/60000]\n",
      "loss: 0.306263  [38464/60000]\n",
      "loss: 0.440628  [44864/60000]\n",
      "loss: 0.502378  [51264/60000]\n",
      "loss: 0.305444  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.402513 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet().to(device)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.9)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303494  [   64/60000]\n",
      "loss: 1.070133  [ 6464/60000]\n",
      "loss: 0.367762  [12864/60000]\n",
      "loss: 0.614635  [19264/60000]\n",
      "loss: 0.588809  [25664/60000]\n",
      "loss: 0.412316  [32064/60000]\n",
      "loss: 0.375863  [38464/60000]\n",
      "loss: 0.725765  [44864/60000]\n",
      "loss: 0.383158  [51264/60000]\n",
      "loss: 0.298515  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.374812 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.395371  [   64/60000]\n",
      "loss: 0.444617  [ 6464/60000]\n",
      "loss: 0.317055  [12864/60000]\n",
      "loss: 0.355231  [19264/60000]\n",
      "loss: 0.204816  [25664/60000]\n",
      "loss: 0.339073  [32064/60000]\n",
      "loss: 0.254414  [38464/60000]\n",
      "loss: 0.308523  [44864/60000]\n",
      "loss: 0.357969  [51264/60000]\n",
      "loss: 0.347962  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.319386 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.348927  [   64/60000]\n",
      "loss: 0.301652  [ 6464/60000]\n",
      "loss: 0.241173  [12864/60000]\n",
      "loss: 0.365154  [19264/60000]\n",
      "loss: 0.159197  [25664/60000]\n",
      "loss: 0.459029  [32064/60000]\n",
      "loss: 0.610119  [38464/60000]\n",
      "loss: 0.857866  [44864/60000]\n",
      "loss: 0.206461  [51264/60000]\n",
      "loss: 0.352326  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.308320 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.436066  [   64/60000]\n",
      "loss: 0.187330  [ 6464/60000]\n",
      "loss: 0.395145  [12864/60000]\n",
      "loss: 0.192806  [19264/60000]\n",
      "loss: 0.284813  [25664/60000]\n",
      "loss: 0.430029  [32064/60000]\n",
      "loss: 0.439068  [38464/60000]\n",
      "loss: 0.345518  [44864/60000]\n",
      "loss: 0.208557  [51264/60000]\n",
      "loss: 0.372322  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306595 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.293654  [   64/60000]\n",
      "loss: 0.281151  [ 6464/60000]\n",
      "loss: 0.295690  [12864/60000]\n",
      "loss: 0.505954  [19264/60000]\n",
      "loss: 0.387870  [25664/60000]\n",
      "loss: 0.450361  [32064/60000]\n",
      "loss: 0.346283  [38464/60000]\n",
      "loss: 0.345506  [44864/60000]\n",
      "loss: 0.285942  [51264/60000]\n",
      "loss: 0.227964  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.309255 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.294824  [   64/60000]\n",
      "loss: 0.135358  [ 6464/60000]\n",
      "loss: 0.454180  [12864/60000]\n",
      "loss: 0.406749  [19264/60000]\n",
      "loss: 0.160943  [25664/60000]\n",
      "loss: 0.237281  [32064/60000]\n",
      "loss: 0.159291  [38464/60000]\n",
      "loss: 0.277280  [44864/60000]\n",
      "loss: 0.254371  [51264/60000]\n",
      "loss: 0.323404  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.289954 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.168286  [   64/60000]\n",
      "loss: 0.315804  [ 6464/60000]\n",
      "loss: 0.137440  [12864/60000]\n",
      "loss: 0.379195  [19264/60000]\n",
      "loss: 0.430049  [25664/60000]\n",
      "loss: 0.261852  [32064/60000]\n",
      "loss: 0.315629  [38464/60000]\n",
      "loss: 0.508549  [44864/60000]\n",
      "loss: 0.238402  [51264/60000]\n",
      "loss: 0.374065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.282575 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.270818  [   64/60000]\n",
      "loss: 0.159311  [ 6464/60000]\n",
      "loss: 0.147366  [12864/60000]\n",
      "loss: 0.193487  [19264/60000]\n",
      "loss: 0.334657  [25664/60000]\n",
      "loss: 0.157965  [32064/60000]\n",
      "loss: 0.338167  [38464/60000]\n",
      "loss: 0.263607  [44864/60000]\n",
      "loss: 0.257247  [51264/60000]\n",
      "loss: 0.492826  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.266791 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.353568  [   64/60000]\n",
      "loss: 0.412673  [ 6464/60000]\n",
      "loss: 0.171383  [12864/60000]\n",
      "loss: 0.241796  [19264/60000]\n",
      "loss: 0.294544  [25664/60000]\n",
      "loss: 0.352330  [32064/60000]\n",
      "loss: 0.375251  [38464/60000]\n",
      "loss: 0.318686  [44864/60000]\n",
      "loss: 0.294642  [51264/60000]\n",
      "loss: 0.188586  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.264412 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.277455  [   64/60000]\n",
      "loss: 0.174621  [ 6464/60000]\n",
      "loss: 0.200312  [12864/60000]\n",
      "loss: 0.269093  [19264/60000]\n",
      "loss: 0.263955  [25664/60000]\n",
      "loss: 0.114438  [32064/60000]\n",
      "loss: 0.165956  [38464/60000]\n",
      "loss: 0.118228  [44864/60000]\n",
      "loss: 0.225472  [51264/60000]\n",
      "loss: 0.363133  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.261699 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),  # 根据输入尺寸计算\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 更改数据处理方式\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "training_data = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

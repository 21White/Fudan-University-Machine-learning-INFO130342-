{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取CIFAR-10数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    # 随机裁剪\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    # 随机水平翻转\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # 归一化\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return nn.ReLU()(out)\n",
    "\n",
    "# 定义模型\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.linear = nn.Linear(512, 10)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, blocks, stride):\n",
    "        strides = [stride] + [1]*(blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = nn.AvgPool2d(4)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练并测试ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310217  [   64/50000]\n",
      "loss: 2.143452  [ 6464/50000]\n",
      "loss: 1.893483  [12864/50000]\n",
      "loss: 2.029742  [19264/50000]\n",
      "loss: 1.751530  [25664/50000]\n",
      "loss: 1.682641  [32064/50000]\n",
      "loss: 1.808219  [38464/50000]\n",
      "loss: 1.640991  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.510957 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.486124  [   64/50000]\n",
      "loss: 1.436495  [ 6464/50000]\n",
      "loss: 1.304010  [12864/50000]\n",
      "loss: 1.362925  [19264/50000]\n",
      "loss: 1.464761  [25664/50000]\n",
      "loss: 1.342310  [32064/50000]\n",
      "loss: 1.360921  [38464/50000]\n",
      "loss: 1.386345  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.280816 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.220246  [   64/50000]\n",
      "loss: 1.226170  [ 6464/50000]\n",
      "loss: 1.128777  [12864/50000]\n",
      "loss: 0.995255  [19264/50000]\n",
      "loss: 1.030885  [25664/50000]\n",
      "loss: 1.011014  [32064/50000]\n",
      "loss: 0.995390  [38464/50000]\n",
      "loss: 1.135408  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 1.428640 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.289135  [   64/50000]\n",
      "loss: 0.901666  [ 6464/50000]\n",
      "loss: 1.202633  [12864/50000]\n",
      "loss: 0.852936  [19264/50000]\n",
      "loss: 1.019318  [25664/50000]\n",
      "loss: 0.749860  [32064/50000]\n",
      "loss: 0.891865  [38464/50000]\n",
      "loss: 0.815215  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.985299 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.236018  [   64/50000]\n",
      "loss: 0.750265  [ 6464/50000]\n",
      "loss: 0.899769  [12864/50000]\n",
      "loss: 0.803062  [19264/50000]\n",
      "loss: 0.747969  [25664/50000]\n",
      "loss: 0.849697  [32064/50000]\n",
      "loss: 0.793458  [38464/50000]\n",
      "loss: 0.749809  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.773052 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.618685  [   64/50000]\n",
      "loss: 0.807518  [ 6464/50000]\n",
      "loss: 0.822967  [12864/50000]\n",
      "loss: 0.626536  [19264/50000]\n",
      "loss: 0.484203  [25664/50000]\n",
      "loss: 0.762177  [32064/50000]\n",
      "loss: 0.626405  [38464/50000]\n",
      "loss: 0.605349  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.760895 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.723372  [   64/50000]\n",
      "loss: 0.613963  [ 6464/50000]\n",
      "loss: 0.705437  [12864/50000]\n",
      "loss: 0.620699  [19264/50000]\n",
      "loss: 0.758132  [25664/50000]\n",
      "loss: 0.646709  [32064/50000]\n",
      "loss: 0.413969  [38464/50000]\n",
      "loss: 0.593059  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.777382 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.577084  [   64/50000]\n",
      "loss: 0.435538  [ 6464/50000]\n",
      "loss: 0.563237  [12864/50000]\n",
      "loss: 0.477901  [19264/50000]\n",
      "loss: 0.468115  [25664/50000]\n",
      "loss: 0.604447  [32064/50000]\n",
      "loss: 0.610962  [38464/50000]\n",
      "loss: 0.576305  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.624307 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.336073  [   64/50000]\n",
      "loss: 0.617630  [ 6464/50000]\n",
      "loss: 0.610599  [12864/50000]\n",
      "loss: 0.570265  [19264/50000]\n",
      "loss: 0.576649  [25664/50000]\n",
      "loss: 0.437443  [32064/50000]\n",
      "loss: 0.506648  [38464/50000]\n",
      "loss: 0.393474  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.569560 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.423207  [   64/50000]\n",
      "loss: 0.497078  [ 6464/50000]\n",
      "loss: 0.491147  [12864/50000]\n",
      "loss: 0.438886  [19264/50000]\n",
      "loss: 0.652363  [25664/50000]\n",
      "loss: 0.456294  [32064/50000]\n",
      "loss: 0.438274  [38464/50000]\n",
      "loss: 0.409136  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.597790 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18()\n",
    "net.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, criterion, optimizer)\n",
    "    test_loop(testloader, net, criterion)\n",
    "    scheduler.step()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
